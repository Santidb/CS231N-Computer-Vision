{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, H = 3, 4, 5\n",
    "x = np.linspace(-0.4, 1.2, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.3, 0.7, num=N*H).reshape(N, H)\n",
    "prev_c = np.linspace(-0.4, 0.9, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-2.1, 1.3, num=4*D*H).reshape(D, 4 * H)\n",
    "Wh = np.linspace(-0.7, 2.2, num=4*H*H).reshape(H, 4 * H)\n",
    "b = np.linspace(0.3, 0.7, num=4*H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = np.dot(x, Wx)\n",
    "h_mat = np.dot(prev_h, Wh)\n",
    "\n",
    "activation = x_mat + h_mat + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 20)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = activation[:, :5]\n",
    "f = activation[:, 5:10]\n",
    "o = activation[:, 10:15]\n",
    "g = activation[:, 15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56210477,  1.52884119,  1.4955776 ,  1.46231401,  1.42905043,\n",
       "         1.39578684,  1.36252325,  1.32925967,  1.29599608,  1.26273249,\n",
       "         1.22946891,  1.19620532,  1.16294173,  1.12967815,  1.09641456,\n",
       "         1.06315097,  1.02988739,  0.9966238 ,  0.96336021,  0.93009663],\n",
       "       [ 0.52201728,  0.6412236 ,  0.76042992,  0.87963624,  0.99884256,\n",
       "         1.11804888,  1.2372552 ,  1.35646152,  1.47566784,  1.59487416,\n",
       "         1.71408048,  1.8332868 ,  1.95249312,  2.07169944,  2.19090576,\n",
       "         2.31011208,  2.42931841,  2.54852473,  2.66773105,  2.78693737],\n",
       "       [-0.51807021, -0.24639399,  0.02528224,  0.29695847,  0.5686347 ,\n",
       "         0.84031092,  1.11198715,  1.38366338,  1.65533961,  1.92701583,\n",
       "         2.19869206,  2.47036829,  2.74204451,  3.01372074,  3.28539697,\n",
       "         3.5570732 ,  3.82874942,  4.10042565,  4.37210188,  4.64377811]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56210477,  1.52884119,  1.4955776 ,  1.46231401,  1.42905043],\n",
       "       [ 0.52201728,  0.6412236 ,  0.76042992,  0.87963624,  0.99884256],\n",
       "       [-0.51807021, -0.24639399,  0.02528224,  0.29695847,  0.5686347 ]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.39578684, 1.36252325, 1.32925967, 1.29599608, 1.26273249],\n",
       "       [1.11804888, 1.2372552 , 1.35646152, 1.47566784, 1.59487416],\n",
       "       [0.84031092, 1.11198715, 1.38366338, 1.65533961, 1.92701583]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22946891, 1.19620532, 1.16294173, 1.12967815, 1.09641456],\n",
       "       [1.71408048, 1.8332868 , 1.95249312, 2.07169944, 2.19090576],\n",
       "       [2.19869206, 2.47036829, 2.74204451, 3.01372074, 3.28539697]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06315097, 1.02988739, 0.9966238 , 0.96336021, 0.93009663],\n",
       "       [2.31011208, 2.42931841, 2.54852473, 2.66773105, 2.78693737],\n",
       "       [3.5570732 , 3.82874942, 4.10042565, 4.37210188, 4.64377811]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_h = output_gate * np.tanhh(next_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_c = np.tanh(next_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_h = output_gate * tan_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b):\n",
    "    \"\"\"\n",
    "    Forward pass for a single timestep of an LSTM.\n",
    "\n",
    "    The input data has dimension D, the hidden state has dimension H, and we use\n",
    "    a minibatch size of N.\n",
    "\n",
    "    Note that a sigmoid() function has already been provided for you in this file.\n",
    "\n",
    "    Inputs:\n",
    "    - x: Input data, of shape (N, D)\n",
    "    - prev_h: Previous hidden state, of shape (N, H)\n",
    "    - prev_c: previous cell state, of shape (N, H)\n",
    "    - Wx: Input-to-hidden weights, of shape (D, 4H)\n",
    "    - Wh: Hidden-to-hidden weights, of shape (H, 4H)\n",
    "    - b: Biases, of shape (4H,)\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - next_h: Next hidden state, of shape (N, H)\n",
    "    - next_c: Next cell state, of shape (N, H)\n",
    "    - cache: Tuple of values needed for backward pass.\n",
    "    \"\"\"\n",
    "    next_h, next_c, cache = None, None, None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the forward pass for a single timestep of an LSTM.        #\n",
    "    # You may want to use the numerically stable sigmoid implementation above.  #\n",
    "    #############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Unpacking dimensions\n",
    "    N, H = prev_h.shape\n",
    "\n",
    "    # Computing activation\n",
    "    x_mat = np.dot(x, Wx)\n",
    "    h_mat = np.dot(prev_h, Wh)\n",
    "\n",
    "    activation = x_mat + h_mat + b\n",
    "\n",
    "    # Computing i, f, o, g gates\n",
    "    input_gate = sigmoid(activation[:, :H])\n",
    "    forget_gate = sigmoid(activation[:, H:2*H])\n",
    "    output_gate = sigmoid(activation[:, 2*H:3*H])\n",
    "    gate_gate = np.tanh(activation[:, 3*H:])\n",
    "\n",
    "    # Next cell state\n",
    "    forget_c = forget_gate * prev_c\n",
    "    ig_c = input_gate * gate_gate\n",
    "    next_c = forget_c + ig_c\n",
    "\n",
    "    # next_c = forget_gate * prev_c + input_gate * gate_gate\n",
    "\n",
    "    # Next hidden state\n",
    "    # next_h = output_gate * np.tanh(next_c)\n",
    "    \n",
    "    tanh_c = np.tanh(next_c)\n",
    "    next_h = output_gate * tanh_c\n",
    "    \n",
    "    # Storing results in cache\n",
    "    cache = (x, prev_h, Wx, Wh, b, prev_c, activation, input_gate, forget_gate, output_gate, gate_gate, next_c, tanh_c)\n",
    "    \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################\n",
    "\n",
    "    return next_h, next_c, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(x, h0, Wx, Wh, b):\n",
    "    \"\"\"\n",
    "    Run a vanilla RNN forward on an entire sequence of data. We assume an input\n",
    "    sequence composed of T vectors, each of dimension D. The RNN uses a hidden\n",
    "    size of H, and we work over a minibatch containing N sequences. After running\n",
    "    the RNN forward, we return the hidden states for all timesteps.\n",
    "\n",
    "    Inputs:\n",
    "    - x: Input data for the entire timeseries, of shape (N, T, D).\n",
    "    - h0: Initial hidden state, of shape (N, H)\n",
    "    - Wx: Weight matrix for input-to-hidden connections, of shape (D, H)\n",
    "    - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H)\n",
    "    - b: Biases of shape (H,)\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - h: Hidden states for the entire timeseries, of shape (N, T, H).\n",
    "    - cache: Values needed in the backward pass\n",
    "    \"\"\"\n",
    "    h, cache = None, None\n",
    "    ##############################################################################\n",
    "    # TODO: Implement forward pass for a vanilla RNN running on a sequence of    #\n",
    "    # input data. You should use the rnn_step_forward function that you defined  #\n",
    "    # above. You can use a for loop to help compute the forward pass.            #\n",
    "    ##############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Extracting dimensions\n",
    "    N, T, D = x.shape\n",
    "    N, H = h0.shape\n",
    "    cache = {}\n",
    "    \n",
    "    # Setting up matrix with hidden states for entire timeseries\n",
    "    h = np.zeros((N, T, H))\n",
    "    h[:, 0, :] = h0\n",
    "\n",
    "    # Iterating over every time dimension\n",
    "    for t in range(T):\n",
    "      \n",
    "      # Extracting x for this time t\n",
    "      x_iter = x[:, t, :]\n",
    "      \n",
    "      # Setting up previous hidden state\n",
    "      if t==0:\n",
    "        prev_h = h0\n",
    "      else:\n",
    "        prev_h = h[:, t-1, :]\n",
    "\n",
    "      # Running an individual forward step\n",
    "      next_h, cache_step = rnn_step_forward(x_iter, prev_h, Wx, Wh, b)\n",
    "\n",
    "      # Storing results\n",
    "      h[:, t, :] = next_h\n",
    "      cache[t] = cache_step\n",
    "    \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################\n",
    "    return h, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_step_backward(dnext_h, dnext_c, cache):\n",
    "    \"\"\"\n",
    "    Backward pass for a single timestep of an LSTM.\n",
    "\n",
    "    Inputs:\n",
    "    - dnext_h: Gradients of next hidden state, of shape (N, H)\n",
    "    - dnext_c: Gradients of next cell state, of shape (N, H)\n",
    "    - cache: Values from the forward pass\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - dx: Gradient of input data, of shape (N, D)\n",
    "    - dprev_h: Gradient of previous hidden state, of shape (N, H)\n",
    "    - dprev_c: Gradient of previous cell state, of shape (N, H)\n",
    "    - dWx: Gradient of input-to-hidden weights, of shape (D, 4H)\n",
    "    - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H)\n",
    "    - db: Gradient of biases, of shape (4H,)\n",
    "    \"\"\"\n",
    "    dx, dprev_h, dprev_c, dWx, dWh, db = None, None, None, None, None, None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the backward pass for a single timestep of an LSTM.       #\n",
    "    #                                                                           #\n",
    "    # HINT: For sigmoid and tanh you can compute local derivatives in terms of  #\n",
    "    # the output value from the nonlinearity.                                   #\n",
    "    #############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Unpacking values from cache\n",
    "    x, prev_h, Wx, Wh, b, prev_c, activation, input_gate, forget_gate, output_gate, gate_gate, next_c, tanh_c = cache\n",
    "    N, H = dnext_h.shape\n",
    "\n",
    "    # 1. next_h = output_gate * tanh_c \n",
    "    doutput_gate = tanh_c * dnext_h\n",
    "    dtanh_c = output_gate * dnext_h\n",
    "\n",
    "    # 2. tanh_c = np.tanh(next_c)\n",
    "    dnext_c_down = (1 - np.tanh(next_c)**2) * dtanh_c\n",
    "    dnext_c_total = dnext_c_down + dnext_c\n",
    "\n",
    "    # 3. next_c = forget_c + ig_c\n",
    "    dforget_c = dnext_c_total\n",
    "    dig_c = dnext_c_total\n",
    "\n",
    "    # 4. ig_c = input_gate * gate_gate\n",
    "    dinput_gate = gate_gate * dig_c\n",
    "    dgate_gate = input_gate * dig_c\n",
    "\n",
    "    # 5. forget_c = forget_gate * prev_c\n",
    "    dforget_gate = prev_c * dforget_c\n",
    "    dprev_c = forget_gate * dforget_c\n",
    "\n",
    "    # 6. Activations \n",
    "    dactivation_i = dinput_gate * sigmoid(activation[:, :H]) * (1 - sigmoid(activation[:, :H])) \n",
    "    dactivation_f = dforget_gate * sigmoid(activation[:, H:2*H]) * (1 - sigmoid(activation[:, H:2*H]))\n",
    "    dactivation_o = doutput_gate * sigmoid(activation[:, 2*H:3*H]) * (1 - sigmoid(activation[:, 2*H:3*H]))\n",
    "    dactivation_g = dgate_gate * (1 - np.tanh(activation[:, 3*H:])**2)\n",
    "    dactivation = np.concatenate((dactivation_i, dactivation_f, dactivation_o, dactivation_g), axis=1)\n",
    "\n",
    "    # 7. activation = x_mat + h_mat + b\n",
    "    dx_mat = 1 * dactivation\n",
    "    dh_mat = 1 * dactivation\n",
    "    db = 1 * np.sum(dactivation, axis=0)\n",
    "\n",
    "    # 8. x_mat = np.dot(x, Wx)\n",
    "    dx = np.dot(dactivation, Wx.T)\n",
    "    dWx = np.dot(x.T, dactivation)\n",
    "    \n",
    "    # h_mat = np.dot(prev_h, Wh)\n",
    "    dprev_h = np.dot(dactivation, Wh.T)\n",
    "    dWh = np.dot(prev_h.T, dactivation)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################\n",
    "\n",
    "    return dx, dprev_h, dprev_c, dWx, dWh, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_backward(dh, cache):\n",
    "    \"\"\"\n",
    "    Compute the backward pass for a vanilla RNN over an entire sequence of data.\n",
    "\n",
    "    Inputs:\n",
    "    - dh: Upstream gradients of all hidden states, of shape (N, T, H). \n",
    "    \n",
    "    NOTE: 'dh' contains the upstream gradients produced by the \n",
    "    individual loss functions at each timestep, *not* the gradients\n",
    "    being passed between timesteps (which you'll have to compute yourself\n",
    "    by calling rnn_step_backward in a loop).\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - dx: Gradient of inputs, of shape (N, T, D)\n",
    "    - dh0: Gradient of initial hidden state, of shape (N, H)\n",
    "    - dWx: Gradient of input-to-hidden weights, of shape (D, H)\n",
    "    - dWh: Gradient of hidden-to-hidden weights, of shape (H, H)\n",
    "    - db: Gradient of biases, of shape (H,)\n",
    "    \"\"\"\n",
    "    dx, dh0, dWx, dWh, db = None, None, None, None, None\n",
    "    ##############################################################################\n",
    "    # TODO: Implement the backward pass for a vanilla RNN running an entire      #\n",
    "    # sequence of data. You should use the rnn_step_backward function that you   #\n",
    "    # defined above. You can use a for loop to help compute the backward pass.   #\n",
    "    ##############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Unpacking dimensions and creating empty vectors\n",
    "    N, T, H = dh.shape\n",
    "    Wx = cache[0][2] # t=0, Wx is at index 2\n",
    "    D, H = Wx.shape\n",
    "\n",
    "    # Creating empty matrices\n",
    "    dx = np.zeros((N,T,D))\n",
    "    dh0 = np.zeros((N,H))\n",
    "    dWx = np.zeros((D,H))\n",
    "    dWh = np.zeros((H,H))\n",
    "    db = np.zeros((H))\n",
    "    dnext_h = np.zeros((N,H))\n",
    "\n",
    "    # Iterating over time dimensions in reverse order\n",
    "    for t in reversed(range(T)):\n",
    "      \n",
    "      # Upstream gradient from individual loss function\n",
    "      dy = dh[:,t,:]\n",
    "      \n",
    "      # Combining horizontal and vertical gradients\n",
    "      # (from next time step and from individual loss function)\n",
    "      dh_all = dnext_h + dy\n",
    "       \n",
    "      # Running single backward step pass\n",
    "      t_dx, dnext_h, t_dWx, t_dWh, t_db = rnn_step_backward(dh_all, cache[t])\n",
    "\n",
    "      # Storing and updating results\n",
    "      dx[:, t, :] = t_dx\n",
    "      dh0 = dnext_h\n",
    "      dWx += t_dWx\n",
    "      dWh += t_dWh\n",
    "      db += t_db\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################\n",
    "    return dx, dh0, dWx, dWh, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_forward(x, h0, Wx, Wh, b):\n",
    "    \"\"\"\n",
    "    Forward pass for an LSTM over an entire sequence of data. We assume an input\n",
    "    sequence composed of T vectors, each of dimension D. The LSTM uses a hidden\n",
    "    size of H, and we work over a minibatch containing N sequences. After running\n",
    "    the LSTM forward, we return the hidden states for all timesteps.\n",
    "\n",
    "    Note that the initial cell state is passed as input, but the initial cell\n",
    "    state is set to zero. Also note that the cell state is not returned; it is\n",
    "    an internal variable to the LSTM and is not accessed from outside.\n",
    "\n",
    "    Inputs:\n",
    "    - x: Input data of shape (N, T, D)\n",
    "    - h0: Initial hidden state of shape (N, H)\n",
    "    - Wx: Weights for input-to-hidden connections, of shape (D, 4H)\n",
    "    - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H)\n",
    "    - b: Biases of shape (4H,)\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - h: Hidden states for all timesteps of all sequences, of shape (N, T, H)\n",
    "    - cache: Values needed for the backward pass.\n",
    "    \"\"\"\n",
    "    h, cache = None, None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the forward pass for an LSTM over an entire timeseries.   #\n",
    "    # You should use the lstm_step_forward function that you just defined.      #\n",
    "    #############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Unpacking dimensions\n",
    "    N, H = h0.shape\n",
    "    N, T, D = x.shape\n",
    "    cache = {}\n",
    "\n",
    "    # Setting up initial values\n",
    "    h          = np.zeros((N, T, H))\n",
    "    h[:, 0, :] = h0\n",
    "\n",
    "    # Iterating over every time dimension\n",
    "    for t in range(T):\n",
    "\n",
    "      # Selecting x for this time step\n",
    "      x_t = x[:, t, :]\n",
    "\n",
    "      # Setting up previous hidden state and cell state\n",
    "      if t==0:\n",
    "        prev_h = h0\n",
    "        prev_c = np.zeros((N, H))\n",
    "      else:\n",
    "        prev_h = h[:, t-1, :]\n",
    "        prev_c = next_c\n",
    "\n",
    "      # Running individual forward step\n",
    "      next_h, next_c, cache_t = lstm_step_forward(x_t, prev_h, prev_c, Wx, Wh, b)\n",
    "\n",
    "      # Storing results\n",
    "      h[:, t, :] = next_h\n",
    "      cache[t] = cache_t\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################\n",
    "\n",
    "    return h, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_backward(dh, cache):\n",
    "    \"\"\"\n",
    "    Backward pass for an LSTM over an entire sequence of data.]\n",
    "\n",
    "    Inputs:\n",
    "    - dh: Upstream gradients of hidden states, of shape (N, T, H)\n",
    "    - cache: Values from the forward pass\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - dx: Gradient of input data of shape (N, T, D)\n",
    "    - dh0: Gradient of initial hidden state of shape (N, H)\n",
    "    - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H)\n",
    "    - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H)\n",
    "    - db: Gradient of biases, of shape (4H,)\n",
    "    \"\"\"\n",
    "    dx, dh0, dWx, dWh, db = None, None, None, None, None\n",
    "    #############################################################################\n",
    "    # TODO: Implement the backward pass for an LSTM over an entire timeseries.  #\n",
    "    # You should use the lstm_step_backward function that you just defined.     #\n",
    "    #############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Unpacking dimensions\n",
    "    N, T, H = dh.shape\n",
    "    Wx = cache[0][2]\n",
    "    D, H_4 = Wx.shape\n",
    "\n",
    "    # Creating empty matrices\n",
    "    dx = np.zeros((N,T,D))\n",
    "    dh0 = np.zeros((N, H))\n",
    "    dWx = np.zeros((D, 4*H))\n",
    "    dWh = np.zeros((H, 4*H))\n",
    "    db = np.zeros((4*H))\n",
    "    dprev_h = np.zeros((N, H))\n",
    "    dprev_c = np.zeros((N, H))\n",
    "\n",
    "    # Iterating over time dimensions in reverse order\n",
    "    for t in reversed(range(T)):\n",
    "\n",
    "      # Upstream gradient from individual loss function\n",
    "      dy = dh[:,t,:]\n",
    "\n",
    "      # Combining horizontal and vertical gradients\n",
    "      dh_all = dprev_h + dy\n",
    "\n",
    "      # Running single backward pass\n",
    "      t_dx, dprev_h, dprev_c, t_dWx, t_dWh, t_db = lstm_step_backward(dh_all, dprev_c, cache[t])\n",
    "\n",
    "      # Storing and updating results\n",
    "      dx[:, t, :] = t_dx\n",
    "      dh0 = dprev_h\n",
    "      dWx += t_dWx\n",
    "      dWh += t_dWh\n",
    "      db += t_db\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                               END OF YOUR CODE                             #\n",
    "    ##############################################################################\n",
    "\n",
    "    return dx, dh0, dWx, dWh, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.squeezenet1_1(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "\n",
    "    # Make input tensor require gradient\n",
    "    X.requires_grad_()\n",
    "\n",
    "    saliency = None\n",
    "    ##############################################################################\n",
    "    # TODO: Implement this function. Perform a forward and backward pass through #\n",
    "    # the model to compute the gradient of the correct class score with respect  #\n",
    "    # to each input image. You first want to compute the loss over the correct   #\n",
    "    # scores (we'll combine losses across a batch by summing), and then compute  #\n",
    "    # the gradients with a backward pass.                                        #\n",
    "    ##############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    # Computing scores for each class\n",
    "    scores = model(X)\n",
    "    \n",
    "    # Obtaining scores corresponding to the true label\n",
    "    scores_true = scores.gather(1, y.view(-1, 1)).squeeze()\n",
    "\n",
    "    # Backpropagating to obtain gradient\n",
    "    scores_true.backward(torch.Tensor([1,1,1,1,1]))\n",
    "\n",
    "    # Obtaining absolute value of gradient\n",
    "    grad = torch.abs(X.grad)\n",
    "\n",
    "    # Take the maximum value over the 3 input channels\n",
    "    saliency, saliency_idx = torch.max(grad, dim=1)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fooling_image(X, target_y, model):\n",
    "    \"\"\"\n",
    "    Generate a fooling image that is close to X, but that the model classifies\n",
    "    as target_y.\n",
    "\n",
    "    Inputs:\n",
    "    - X: Input image; Tensor of shape (1, 3, 224, 224)\n",
    "    - target_y: An integer in the range [0, 1000)\n",
    "    - model: A pretrained CNN\n",
    "\n",
    "    Returns:\n",
    "    - X_fooling: An image that is close to X, but that is classifed as target_y\n",
    "    by the model.\n",
    "    \"\"\"\n",
    "    # Initialize our fooling image to the input image, and make it require gradient\n",
    "    X_fooling = X.clone()\n",
    "    X_fooling = X_fooling.requires_grad_()\n",
    "\n",
    "    learning_rate = 1\n",
    "    ##############################################################################\n",
    "    # TODO: Generate a fooling image X_fooling that the model will classify as   #\n",
    "    # the class target_y. You should perform gradient ascent on the score of the #\n",
    "    # target class, stopping when the model is fooled.                           #\n",
    "    # When computing an update step, first normalize the gradient:               #\n",
    "    #   dX = learning_rate * g / ||g||_2                                         #\n",
    "    #                                                                            #\n",
    "    # You should write a training loop.                                          #\n",
    "    #                                                                            #\n",
    "    # HINT: For most examples, you should be able to generate a fooling image    #\n",
    "    # in fewer than 100 iterations of gradient ascent.                           #\n",
    "    # You can print your progress over iterations to check your algorithm.       #\n",
    "    ##############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Establishing number of iterations\n",
    "    T = 100\n",
    "\n",
    "    # Running loop over all iterations\n",
    "    for t in range(T):\n",
    "\n",
    "      # Forward pass\n",
    "      scores = model(X_fooling)\n",
    "\n",
    "      # Computing predicted y\n",
    "      pred_y = torch.argmax(scores, dim=1)\n",
    "\n",
    "      # If predicted y is the same as fooling y, we are done\n",
    "      if pred_y[0] == target_y:\n",
    "        break\n",
    "\n",
    "      # Get the score for target_y\n",
    "      target_score = scores[0][target_y]\n",
    "\n",
    "      # Zeroing gradients before doing backward pass\n",
    "      model.zero_grad()\n",
    "\n",
    "      # Backward pass\n",
    "      target_score.backward()\n",
    "\n",
    "      grad = X_fooling.grad\n",
    "      \n",
    "      # Performing gradient ascent\n",
    "      with torch.no_grad():\n",
    "        grad = X_fooling.grad\n",
    "        X_fooling += learning_rate * grad / grad.norm()\n",
    "        \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return X_fooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.arange(9).reshape((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1643623])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(logits_real, logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the discriminator loss described above.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
    "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Tensor containing (scalar) the loss for the discriminator.\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # Obtaining dimension\n",
    "    size = logits_real.shape[0]\n",
    "    \n",
    "    # Initializing true label vector\n",
    "    true_labels = torch.ones(size).type(dtype)\n",
    "\n",
    "    # First term - classifying the real image\n",
    "    bce_real = bce_loss(logits_real, true_labels)\n",
    "    bce_fake = bce_loss(logits_fake, 1 - true_labels)\n",
    "\n",
    "    # Computing loss\n",
    "    loss = bce_real + bce_fake\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
